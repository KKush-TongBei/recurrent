"""
è®­ç»ƒè„šæœ¬
ç”¨äºè®­ç»ƒCMFFAæ¨¡å‹
"""

import os
import argparse
import yaml
import random
import torch

# é™åˆ¶ CPU çº¿ç¨‹ï¼Œé¿å…é£æ‰‡èµ·é£/CPU æ»¡è½½ï¼ˆä¸æ”¹æ¨¡å‹é€»è¾‘ï¼‰
os.environ["OMP_NUM_THREADS"] = "4"
os.environ["MKL_NUM_THREADS"] = "4"
torch.set_num_threads(4)

import torch.nn as nn
# è®ºæ–‡4.3.2èŠ‚ï¼šä½¿ç”¨ Adam ä¼˜åŒ–å™¨ï¼ˆé AdamWï¼Œè®ºæ–‡æœªæåŠ weight_decay/AdamWï¼‰
from torch.optim import Adam
from transformers import BertTokenizer
from tqdm import tqdm
import numpy as np
from pathlib import Path

from models.cmffa import CMFFA
from data.dataset import create_dataloader, create_cached_dataloader
from utils.logger import setup_logger
from utils.visualization import plot_training_curves


def load_config(config_path: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def get_balanced_class_weights(train_path: str, num_classes: int = 2) -> torch.Tensor:
    """
    ä»è®­ç»ƒé›† JSON ç»Ÿè®¡å„ç±»åˆ«æ•°é‡ï¼Œè¿”å›å¹³è¡¡ç±»åˆ«æƒé‡çš„å¼ é‡ [num_classes]ã€‚
    weight_i = n_samples / (num_classes * n_i)ï¼Œå°‘æ•°ç±»æƒé‡å¤§ï¼Œç¼“è§£å…¨é¢„æµ‹å¤šæ•°ç±»ã€‚
    """
    import json
    with open(train_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    if not isinstance(data, list):
        return None
    counts = [0] * num_classes
    for item in data:
        label = int(item.get('label', 0))
        if 0 <= label < num_classes:
            counts[label] += 1
    n = sum(counts)
    if n == 0 or min(counts) == 0:
        return None
    # weight_i = n / (num_classes * n_i)
    weights = [n / (num_classes * c) for c in counts]
    return torch.tensor(weights, dtype=torch.float32)


def get_bert_model_name(data_path: str, config: dict) -> str:
    """
    æ ¹æ®æ•°æ®é›†è·¯å¾„è‡ªåŠ¨é€‰æ‹©BERTæ¨¡å‹
    è®ºæ–‡è¦æ±‚ï¼šä¸­æ–‡"æŒ‰å­—åˆ‡åˆ†"ã€è‹±æ–‡"WordPieceåˆ‡åˆ†"
    
    Args:
        data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ "data/weibo/train.json"ï¼‰
        config: é…ç½®å­—å…¸
    
    Returns:
        bert_model_name: BERTæ¨¡å‹åç§°
    """
    # æ£€æŸ¥configä¸­æ˜¯å¦æ˜ç¡®æŒ‡å®šäº†æ¨¡å‹ï¼ˆä¸”ä¸æ˜¯"auto"ï¼‰
    if 'model' in config and 'text_encoder' in config['model']:
        explicit_model = config['model']['text_encoder'].get('model_name')
        # åªæœ‰å½“æ˜¾å¼æŒ‡å®šä¸”ä¸æ˜¯"auto"æˆ–ç©ºå­—ç¬¦ä¸²æ—¶ï¼Œæ‰ä½¿ç”¨æ˜¾å¼å€¼
        if explicit_model and str(explicit_model).lower() not in ['auto', '']:
            return str(explicit_model)
    
    # æ ¹æ®æ•°æ®è·¯å¾„è‡ªåŠ¨åˆ¤æ–­ï¼ˆè®ºæ–‡è¦æ±‚ï¼šWeiboç”¨ä¸­æ–‡BERTï¼ŒPheme/Gossipcopç”¨è‹±æ–‡BERTï¼‰
    data_path_lower = data_path.lower()
    if 'weibo' in data_path_lower:
        return 'bert-base-chinese'  # ä¸­æ–‡æ•°æ®é›†ï¼šæŒ‰å­—åˆ‡åˆ†
    elif 'gossipcop' in data_path_lower or 'pheme' in data_path_lower:
        return 'bert-base-uncased'  # è‹±æ–‡æ•°æ®é›†ï¼šWordPieceåˆ‡åˆ†
    else:
        # é»˜è®¤ä½¿ç”¨è‹±æ–‡BERTï¼ˆå‘åå…¼å®¹ï¼‰
        return 'bert-base-uncased'


def get_learning_rate(data_path: str, config: dict) -> float:
    """
    æ ¹æ®æ•°æ®é›†è‡ªåŠ¨é€‰æ‹©å­¦ä¹ ç‡
    è®ºæ–‡4.3.2èŠ‚ï¼šWeibo lr=0.001, Pheme lr=0.002
    
    Args:
        data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
        config: é…ç½®å­—å…¸
    
    Returns:
        learning_rate: å­¦ä¹ ç‡
    """
    # æ£€æŸ¥configä¸­æ˜¯å¦æ˜ç¡®æŒ‡å®šäº†å­¦ä¹ ç‡ï¼ˆä¸”ä¸æ˜¯"auto"ï¼‰
    explicit_lr = config.get('training', {}).get('learning_rate')
    # åªæœ‰å½“æ˜¾å¼æŒ‡å®šä¸”ä¸æ˜¯"auto"æˆ–Noneæ—¶ï¼Œæ‰ä½¿ç”¨æ˜¾å¼å€¼
    if explicit_lr is not None:
        explicit_lr_str = str(explicit_lr).lower()
        if explicit_lr_str not in ['auto', '']:
            try:
                return float(explicit_lr)
            except (ValueError, TypeError):
                # å¦‚æœæ— æ³•è½¬æ¢ä¸ºfloatï¼Œç»§ç»­è‡ªåŠ¨é€‰æ‹©
                pass
    
    # æ ¹æ®æ•°æ®è·¯å¾„è‡ªåŠ¨åˆ¤æ–­ï¼ˆè®ºæ–‡4.3.2èŠ‚æ˜ç¡®è¯´æ˜ï¼‰
    data_path_lower = data_path.lower()
    if 'weibo' in data_path_lower:
        return 0.001  # è®ºæ–‡4.3.2èŠ‚ï¼šWeiboå­¦ä¹ ç‡
    elif 'pheme' in data_path_lower:
        return 0.002  # è®ºæ–‡4.3.2èŠ‚ï¼šPhemeå­¦ä¹ ç‡
    else:
        # Gossipcopæˆ–å…¶ä»–æ•°æ®é›†ï¼Œé»˜è®¤ä½¿ç”¨0.001ï¼ˆè®ºæ–‡æœªæ˜ç¡®è¯´æ˜Gossipcopçš„å­¦ä¹ ç‡ï¼‰
        return 0.001


def pgd_attack(
    model: nn.Module,
    input_ids: torch.Tensor,
    attention_mask: torch.Tensor,
    images: torch.Tensor,
    labels: torch.Tensor,
    text_strings: list,
    criterion: nn.Module,
    epsilon: float = 0.01,
    alpha: float = 0.003,
    num_steps: int = 3
) -> torch.Tensor:
    """
    PGDå¯¹æŠ—æ”»å‡»ï¼šå¯¹BERTæ–‡æœ¬åµŒå…¥æ·»åŠ æ‰°åŠ¨
    æŒ‰ç…§è®ºæ–‡è¦æ±‚ï¼šå¯¹æ–‡æœ¬åµŒå…¥åšPGDå¯¹æŠ—è®­ç»ƒæ¥å¢å¼ºé²æ£’æ€§
    
    Args:
        model: CMFFAæ¨¡å‹
        input_ids: æ–‡æœ¬token IDs
        attention_mask: æ³¨æ„åŠ›æ©ç 
        images: å›¾åƒ
        labels: æ ‡ç­¾
        text_strings: åŸå§‹æ–‡æœ¬å­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆç”¨äºCLIPï¼‰
        criterion: æŸå¤±å‡½æ•°
        epsilon: æ‰°åŠ¨ä¸Šé™
        alpha: æ¯æ¬¡è¿­ä»£æ­¥é•¿
        num_steps: PGDè¿­ä»£æ¬¡æ•°
    
    Returns:
        perturbed_embeddings: æ‰°åŠ¨åçš„åµŒå…¥ [batch_size, seq_len, hidden_size]
    """
    # è·å–BERTçš„embeddingå±‚
    text_encoder = model.text_encoder
    bert_model = text_encoder.bert
    embeddings = bert_model.embeddings
    
    # è·å–å®Œæ•´çš„åŸå§‹embeddingsï¼ˆåŒ…å«word + position + token_typeï¼‰
    # é€šè¿‡ä¸€æ¬¡å‰å‘ä¼ æ’­è·å–ï¼Œç¡®ä¿åŒ…å«æ‰€æœ‰embeddingç»„ä»¶
    with torch.no_grad():
        # ä¸´æ—¶hookè·å–å®Œæ•´embeddingsè¾“å‡ºï¼ˆembeddingså±‚çš„æœ€ç»ˆè¾“å‡ºï¼‰
        full_embeddings_list = []
        def get_full_embeddings(module, input, output):
            full_embeddings_list.append(output.clone())
            return output
        
        handle_temp = embeddings.register_forward_hook(get_full_embeddings)
        try:
            # ä½¿ç”¨token_type_ids=0ï¼ˆå•å¥ä»»åŠ¡ï¼‰
            token_type_ids = torch.zeros_like(input_ids, device=input_ids.device)
            _ = bert_model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)
        finally:
            handle_temp.remove()
        
        if len(full_embeddings_list) > 0:
            original_embeddings = full_embeddings_list[0]  # [batch_size, seq_len, hidden_size]
        else:
            # å¦‚æœhookæœªè§¦å‘ï¼Œå›é€€åˆ°word_embeddingsï¼ˆå‘åå…¼å®¹ï¼‰
            original_embeddings = embeddings.word_embeddings(input_ids)
    
    # åˆå§‹åŒ–æ‰°åŠ¨ï¼ˆéšæœºåˆå§‹åŒ–ï¼‰
    delta = torch.zeros_like(original_embeddings, requires_grad=True)
    
    # PGDè¿­ä»£æ”»å‡»
    for step in range(num_steps):
        # è®¡ç®—å½“å‰åµŒå…¥ï¼ˆåŸå§‹ + æ‰°åŠ¨ï¼‰
        perturbed_embeddings = original_embeddings + delta
        
        # åˆ›å»ºhookæ¥æ›¿æ¢embeddingå±‚çš„æœ€ç»ˆè¾“å‡ºï¼ˆåŒ…å«position/token_typeä¹‹åï¼‰
        # è¿™ç¡®ä¿æ‰°åŠ¨ä½œç”¨åœ¨å®Œæ•´çš„embeddingsä¸Šï¼Œä¸BERTçœŸå®embeddingç®¡çº¿ä¸€è‡´
        def embedding_hook(module, input, output):
            # è¿”å›æ‰°åŠ¨åçš„å®Œæ•´embeddingsï¼ˆåŒ…å«æ‰€æœ‰ç»„ä»¶ï¼‰
            return perturbed_embeddings
        
        # æ³¨å†Œhook
        handle = embeddings.register_forward_hook(embedding_hook)
        
        try:
            # å‰å‘ä¼ æ’­è®¡ç®—æŸå¤±
            output = model(input_ids, attention_mask, images, text_strings=text_strings)
            logits = output['logits']  # [batch_size, 2]
            loss = criterion(logits, labels)  # CrossEntropyLosséœ€è¦longç±»å‹çš„labels
            
            # åªå¯¹deltaæ±‚æ¢¯åº¦ï¼Œä¸æ±¡æŸ“æ¨¡å‹å‚æ•°æ¢¯åº¦ï¼ˆè®ºæ–‡è§„èŒƒçš„PGDå®ç°ï¼‰
            # ä½¿ç”¨torch.autograd.gradåªè®¡ç®—deltaçš„æ¢¯åº¦
            delta_grad = torch.autograd.grad(
                outputs=loss,
                inputs=delta,
                retain_graph=False,
                create_graph=False,
                only_inputs=True
            )[0]
            
            # æ›´æ–°æ‰°åŠ¨ï¼ˆæ¢¯åº¦ä¸Šå‡ï¼‰
            if delta_grad is not None:
                delta.data = delta.data + alpha * delta_grad.sign()
                # æŠ•å½±åˆ°epsilonçƒå†…
                delta.data = torch.clamp(delta.data, -epsilon, epsilon)
                delta.grad = None  # æ¸…é™¤æ¢¯åº¦
        finally:
            # ç§»é™¤hook
            handle.remove()
    
    return delta.detach()


def create_model(config: dict) -> CMFFA:
    """åˆ›å»ºæ¨¡å‹"""
    model = CMFFA(
        text_encoder_config=config['model']['text_encoder'],
        image_encoder_config=config['model']['image_encoder'],
        clip_config=config['model']['clip'],
        fusion_config=config['model']['fusion'],
        attention_config=config['model']['attention'],
        classifier_config=config['model']['classifier']
    )
    return model


def train_epoch(
    model: nn.Module,
    dataloader: torch.utils.data.DataLoader,
    criterion: nn.Module,
    optimizer: torch.optim.Optimizer,
    device: torch.device,
    logger,
    pgd_config: dict = None,
    strict_paper_mode: bool = False,
    max_grad_norm: float = 1.0,
    grad_accum_steps: int = 1,
    use_cached_features: bool = False
) -> tuple:
    """è®­ç»ƒä¸€ä¸ªepochã€‚grad_accum_steps>1 æ—¶ç­‰æ•ˆå¤§ batchï¼›use_cached_features æ—¶ç”¨é¢„è®¡ç®—ç‰¹å¾ã€ä¸è·‘ encoderã€ç¦ç”¨ PGDã€‚"""
    model.train()
    total_loss = 0.0
    correct = 0
    total = 0
    
    # PGD ä»…åœ¨åŸå§‹è¾“å…¥ä¸‹å¯ç”¨ï¼ˆç¼“å­˜ç‰¹å¾æ—¶æ—  BERT åµŒå…¥å¯æ‰°åŠ¨ï¼‰
    use_pgd = not use_cached_features and pgd_config is not None and pgd_config.get('enabled', False)
    pgd_epsilon = pgd_config.get('epsilon', 0.01) if use_pgd else 0.01
    pgd_alpha = pgd_config.get('alpha', 0.003) if use_pgd else 0.003
    pgd_steps = pgd_config.get('steps', 3) if use_pgd else 3
    
    optimizer.zero_grad()
    pbar = tqdm(dataloader, desc="Training")
    for step, batch in enumerate(pbar):
        labels = batch['label'].to(device)
        if use_cached_features:
            bert_after = batch['bert_after_layer10'].to(device)
            resnet_after = batch['resnet_after_layer3'].to(device)
            text_macro = batch['text_macro'].to(device)
            image_macro = batch['image_macro'].to(device)
            attn_mask = batch.get('attention_mask')
            if attn_mask is not None:
                attn_mask = attn_mask.to(device)
            output = model.forward_from_partial_encoder(bert_after, resnet_after, text_macro, image_macro, attention_mask=attn_mask)
        else:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            images = batch['image'].to(device)
            text_strings = batch.get('text', None)
            if text_strings is not None and isinstance(text_strings, str):
                text_strings = [text_strings]
            output = model(input_ids, attention_mask, images, text_strings=text_strings)
        logits = output['logits']  # [batch_size, 2]
        loss = criterion(logits, labels) / grad_accum_steps  # æ¢¯åº¦ç´¯ç§¯æ—¶æŒ‰æ­¥ç¼©æ”¾
        
        # PGDå¯¹æŠ—è®­ç»ƒï¼ˆä»…åŸå§‹è¾“å…¥æ—¶ï¼šå¯¹æ–‡æœ¬åµŒå…¥åšPGDï¼›ç¼“å­˜ç‰¹å¾æ—¶è·³è¿‡ï¼‰
        if use_pgd:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            images = batch['image'].to(device)
            text_strings = batch.get('text', None)
            if isinstance(text_strings, str):
                text_strings = [text_strings]
            delta = pgd_attack(
                model, input_ids, attention_mask, images, labels, text_strings,
                criterion, pgd_epsilon, pgd_alpha, pgd_steps
            )
            text_encoder = model.text_encoder
            bert_model = text_encoder.bert
            embeddings = bert_model.embeddings
            with torch.no_grad():
                full_embeddings_list = []
                def get_full_embeddings(module, input, output):
                    full_embeddings_list.append(output.clone())
                    return output
                handle_get = embeddings.register_forward_hook(get_full_embeddings)
                try:
                    token_type_ids = torch.zeros_like(input_ids, device=input_ids.device)
                    _ = bert_model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)
                finally:
                    handle_get.remove()
                full_embeddings = full_embeddings_list[0]
            perturbed_embeddings = full_embeddings + delta
            def embedding_hook(module, input, output):
                return perturbed_embeddings
            handle = embeddings.register_forward_hook(embedding_hook)
            try:
                adv_output = model(input_ids, attention_mask, images, text_strings=text_strings)
                adv_logits = adv_output['logits']
                adv_loss = criterion(adv_logits, labels) / grad_accum_steps
                total_loss_batch = loss + adv_loss
            finally:
                handle.remove()
        else:
            total_loss_batch = loss
        
        # åå‘ä¼ æ’­ï¼ˆæ¢¯åº¦ç´¯ç§¯ï¼‰
        total_loss_batch.backward()
        
        # æ¯ grad_accum_steps æ­¥æˆ–æœ€åä¸€æ­¥æ‰æ›´æ–°å‚æ•°
        if (step + 1) % grad_accum_steps == 0 or (step + 1) == len(dataloader):
            if not strict_paper_mode:
                torch.nn.utils.clip_grad_norm_(
                    model.parameters(),
                    max_norm=max_grad_norm
                )
            optimizer.step()
            optimizer.zero_grad()
        
        # ç»Ÿè®¡ï¼ˆæŒ‰æœªç¼©æ”¾ loss æ˜¾ç¤ºï¼‰
        total_loss += total_loss_batch.item() * grad_accum_steps
        # è®ºæ–‡å…¬å¼(22)ï¼šsoftmaxè¾“å‡ºï¼Œargmaxå¾—åˆ°é¢„æµ‹ç±»åˆ«
        predictions = torch.argmax(logits, dim=-1)
        correct += (predictions == labels).sum().item()
        total += labels.size(0)
        
        # æ›´æ–°è¿›åº¦æ¡
        pbar.set_postfix({
            'loss': f'{total_loss_batch.item():.4f}',
            'acc': f'{100 * correct / total:.2f}%'
        })
    
    avg_loss = total_loss / len(dataloader)
    accuracy = correct / total
    
    return avg_loss, accuracy


def validate(
    model: nn.Module,
    dataloader: torch.utils.data.DataLoader,
    criterion: nn.Module,
    device: torch.device,
    logger,
    use_cached_features: bool = False
) -> tuple:
    """éªŒè¯ã€‚use_cached_features æ—¶ç”¨ forward_from_partial_encoderã€‚"""
    model.eval()
    total_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        pbar = tqdm(dataloader, desc="Validating")
        for batch in pbar:
            labels = batch['label'].to(device)
            if use_cached_features:
                bert_after = batch['bert_after_layer10'].to(device)
                resnet_after = batch['resnet_after_layer3'].to(device)
                text_macro = batch['text_macro'].to(device)
                image_macro = batch['image_macro'].to(device)
                attn_mask = batch.get('attention_mask')
                if attn_mask is not None:
                    attn_mask = attn_mask.to(device)
                output = model.forward_from_partial_encoder(bert_after, resnet_after, text_macro, image_macro, attention_mask=attn_mask)
            else:
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                images = batch['image'].to(device)
                text_strings = batch.get('text', None)
                if text_strings is not None and isinstance(text_strings, str):
                    text_strings = [text_strings]
                output = model(input_ids, attention_mask, images, text_strings=text_strings)
            logits = output['logits']  # [batch_size, 2]
            
            # è®¡ç®—æŸå¤±
            loss = criterion(logits, labels)  # CrossEntropyLosséœ€è¦longç±»å‹çš„labels
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            # è®ºæ–‡å…¬å¼(22)ï¼šsoftmaxè¾“å‡ºï¼Œargmaxå¾—åˆ°é¢„æµ‹ç±»åˆ«
            predictions = torch.argmax(logits, dim=-1)
            correct += (predictions == labels).sum().item()
            total += labels.size(0)
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'acc': f'{100 * correct / total:.2f}%'
            })
    
    avg_loss = total_loss / len(dataloader)
    accuracy = correct / total
    
    return avg_loss, accuracy


def save_checkpoint(
    model: nn.Module,
    optimizer: torch.optim.Optimizer,
    epoch: int,
    loss: float,
    save_path: str
):
    """ä¿å­˜æ£€æŸ¥ç‚¹"""
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
    }, save_path)
    print(f"Checkpoint saved to {save_path}")


def parse_args():
    parser = argparse.ArgumentParser(description='Train CMFFA model')
    parser.add_argument('--config', type=str, default='config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--resume', type=str, default=None, metavar='PATH', help='ä»è¯¥ checkpoint ç»§ç»­è®­ç»ƒï¼ˆå¦‚ checkpoints/best_model.ptï¼‰')
    return parser.parse_args()


def main():
    args = parse_args()
    config_path = getattr(args, 'config', 'config.yaml')
    config = load_config(config_path)
    
    # è®¾ç½®è®¾å¤‡ï¼šCUDA > MPSï¼ˆApple Siliconï¼‰> CPUï¼ŒMPS ä¸‹ä¿æŒè®ºæ–‡è¶…å‚ä¸”å‡è½» CPU è´Ÿè½½
    if torch.cuda.is_available():
        device = torch.device('cuda')
    elif getattr(torch.backends, 'mps', None) is not None and torch.backends.mps.is_available():
        device = torch.device('mps')
    else:
        device = torch.device(config['training'].get('device', 'cpu'))
    print(f"Using device: {device}")
    
    # å›ºå®šéšæœºç§å­ï¼ˆè®ºæ–‡4.3.2èŠ‚ï¼šseed=42ï¼Œä¿è¯è®­ç»ƒå…¨ç¨‹å¯å¤ç°ï¼‰
    random.seed(42)
    np.random.seed(42)
    torch.manual_seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(42)
        torch.cuda.manual_seed_all(42)
    torch.backends.cudnn.deterministic = True  # å¯å¤ç°ï¼Œç•¥æ…¢
    torch.backends.cudnn.benchmark = False
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logger(
        'train',
        log_dir=config['training']['log_dir'],
        log_to_file=True
    )
    
    # æ ¹æ®æ•°æ®é›†è‡ªåŠ¨é€‰æ‹©BERTæ¨¡å‹ï¼ˆè®ºæ–‡è¦æ±‚ï¼šä¸­æ–‡æŒ‰å­—åˆ‡åˆ†ï¼Œè‹±æ–‡WordPieceåˆ‡åˆ†ï¼‰
    bert_model_name = get_bert_model_name(config['data']['train_path'], config)
    # æ›´æ–°configä¸­çš„æ¨¡å‹åç§°ï¼Œç¡®ä¿æ¨¡å‹å’Œtokenizerä½¿ç”¨ç›¸åŒçš„BERT
    config['model']['text_encoder']['model_name'] = bert_model_name
    logger.info(f"Using BERT model: {bert_model_name} (auto-selected based on dataset)")
    
    # åŠ è½½tokenizerï¼ˆä¼˜å…ˆæœ¬åœ°ç¼“å­˜ï¼Œé¿å…æ— ç½‘æ—¶åå¤é‡è¯• huggingface.coï¼‰
    logger.info("Loading tokenizer...")
    tokenizer = BertTokenizer.from_pretrained(bert_model_name, local_files_only=True)
    logger.info("Tokenizer loaded.")
    
    # è·å–strict_paper_modeé…ç½®ï¼ˆä¸¥æ ¼éµå¾ªè®ºæ–‡è®¾ç½®ï¼‰
    strict_paper_mode = config.get('training', {}).get('strict_paper_mode', False)
    if strict_paper_mode:
        logger.info("="*50)
        logger.info("STRICT PAPER MODE ENABLED")
        logger.info("Following paper settings exactly:")
        logger.info("- Chinese text: character-level tokenization (æŒ‰å­—åˆ‡åˆ†)")
        logger.info("- Image preprocessing: resize only (224x224), no augmentation")
        logger.info("- Training: no weight_decay, no warmup, no grad_clip (paper not mentioned)")
        logger.info("="*50)
    
    # è‹¥é…ç½®äº†ç‰¹å¾ç¼“å­˜ä¸”å­˜åœ¨ train.ptï¼Œåˆ™ç”¨é¢„è®¡ç®—ç‰¹å¾ï¼ˆä¸å†è·‘ BERT/ResNet/CLIPï¼Œå•æ­¥å¿«ä¸€ä¸ªæ•°é‡çº§ï¼‰
    data_cfg = config['data']
    feature_cache_dir = data_cfg.get('feature_cache_dir', '')
    train_cache_path = os.path.join(feature_cache_dir, 'train.pt') if feature_cache_dir else ''
    use_cached_features = bool(feature_cache_dir and os.path.exists(train_cache_path))
    if use_cached_features:
        logger.info(f"Using partial encoder cache from {feature_cache_dir} (BERT 0â€“10, ResNet 0â€“3 + CLIP); training runs BERT 11 + ResNet 4 + fusion.")
        val_cache_path = os.path.join(feature_cache_dir, 'val.pt')
        logger.info("Loading train cache (train.pt)...")
        train_loader = create_cached_dataloader(
            train_cache_path,
            batch_size=data_cfg['batch_size'],
            num_workers=data_cfg.get('num_workers', 4),
            is_training=True,
            shuffle=True,
            device=device
        )
        logger.info("Train cache loaded.")
        logger.info("Loading val cache (val.pt)...")
        val_loader = create_cached_dataloader(
            val_cache_path,
            batch_size=data_cfg['batch_size'],
            num_workers=data_cfg.get('num_workers', 4),
            is_training=False,
            shuffle=False,
            device=device
        ) if os.path.exists(val_cache_path) else None
        if val_loader is not None:
            logger.info("Val cache loaded.")
        if val_loader is None:
            logger.warning(f"Val cache not found at {val_cache_path}; validation will be skipped.")
    else:
        train_loader = create_dataloader(
            data_path=data_cfg['train_path'],
            image_dir=data_cfg['image_dir'],
            tokenizer=tokenizer,
            max_text_length=data_cfg['max_text_length'],
            image_size=data_cfg['image_size'],
            batch_size=data_cfg['batch_size'],
            num_workers=data_cfg.get('num_workers', 4),
            is_training=True,
            shuffle=True,
            strict_paper_mode=strict_paper_mode,
            device=device
        )
        val_loader = create_dataloader(
            data_path=data_cfg['val_path'],
            image_dir=data_cfg['image_dir'],
            tokenizer=tokenizer,
            max_text_length=data_cfg['max_text_length'],
            image_size=data_cfg['image_size'],
            batch_size=data_cfg['batch_size'],
            num_workers=data_cfg.get('num_workers', 4),
            is_training=False,
            shuffle=False,
            strict_paper_mode=strict_paper_mode,
            device=device
        )
    
    # åˆ›å»ºæ¨¡å‹ï¼ˆå« BERT/ResNet/CLIPï¼Œé¦–æ¬¡æˆ–åŠ è½½æƒé‡å¯èƒ½è¾ƒæ…¢ï¼‰
    logger.info("Creating model...")
    model = create_model(config)
    logger.info("Model created, moving to device...")
    model = model.to(device)
    logger.info("Model ready.")
    
    # å¯é€‰ï¼šå†»ç»“ BERT + ResNetï¼Œåªè®­ç»ƒèåˆ/æ³¨æ„åŠ›/VAE/åˆ†ç±»å™¨ï¼ˆæé€Ÿæ˜æ˜¾ï¼Œæ€è·¯ä¸å˜ï¼‰
    freeze_encoders = config.get('training', {}).get('freeze_encoders', False)
    if freeze_encoders:
        for p in model.text_encoder.parameters():
            p.requires_grad = False
        for p in model.image_encoder.parameters():
            p.requires_grad = False
        logger.info("Frozen text_encoder (BERT) and image_encoder (ResNet); only fusion/attention/VAE/classifier are trained.")

    def unfreeze_encoder_last_layers(model):
        """è§£å†» BERT æœ€åä¸€å±‚ + ResNet æœ€åä¸€ä¸ª blockï¼Œè¿”å›æ–°å¯è®­ç»ƒå‚æ•°åˆ—è¡¨ï¼ˆç”¨äºåŠ å…¥ä¼˜åŒ–å™¨ï¼‰ã€‚"""
        newly_trainable = []
        if hasattr(model.text_encoder, 'bert') and hasattr(model.text_encoder.bert, 'encoder'):
            last_layer = model.text_encoder.bert.encoder.layer[-1]
            for p in last_layer.parameters():
                p.requires_grad = True
                newly_trainable.append(p)
        if hasattr(model.image_encoder, 'resnet_backbone'):
            children = list(model.image_encoder.resnet_backbone.children())
            if children:
                last_block = children[-1]
                for p in last_block.parameters():
                    p.requires_grad = True
                    newly_trainable.append(p)
        return newly_trainable
    
    # æŸå¤±å‡½æ•°ï¼ˆè®ºæ–‡å…¬å¼23ï¼šäº¤å‰ç†µæŸå¤±ï¼‰
    # è®ºæ–‡å…¬å¼(22)ï¼šğ‘¦Ì‚ = ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥(ğ¹ğ¶ğ‘ (ğ¹))
    # è®ºæ–‡å…¬å¼(23)ï¼šâ„’cls = ğ‘¦ğ‘™ğ‘œğ‘”(ğ‘¦Ì‚ ) + (1 âˆ’ ğ‘¦)ğ‘™ğ‘œğ‘”(1 âˆ’ ğ‘¦Ì‚ )
    # å¯é€‰ï¼šç±»åˆ«æƒé‡ï¼Œè®©æ¨¡å‹æ›´åœ¨æ„å°‘æ•°ç±»ï¼ˆFakeï¼‰ï¼Œç¼“è§£å…¨é¢„æµ‹ Realï¼‰
    num_classes = config['model']['classifier'].get('num_classes', 2)
    class_weight = config.get('training', {}).get('class_weight', None)
    if class_weight == 'balanced':
        train_path = data_cfg['train_path']
        if not os.path.isabs(train_path):
            train_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), train_path)
        weight_tensor = get_balanced_class_weights(train_path, num_classes)
        if weight_tensor is not None:
            weight_tensor = weight_tensor.to(device)
            criterion = nn.CrossEntropyLoss(weight=weight_tensor)
            logger.info(f"Using CrossEntropyLoss with balanced class_weight: {weight_tensor.tolist()}")
        else:
            criterion = nn.CrossEntropyLoss()
            logger.info("Using CrossEntropyLoss (balanced weight computation failed, using no weight)")
    elif isinstance(class_weight, (list, tuple)) and len(class_weight) == num_classes:
        weight_tensor = torch.tensor(class_weight, dtype=torch.float32, device=device)
        criterion = nn.CrossEntropyLoss(weight=weight_tensor)
        logger.info(f"Using CrossEntropyLoss with class_weight: {class_weight}")
    else:
        criterion = nn.CrossEntropyLoss()
        logger.info("Using CrossEntropyLoss (no class weight)")
    
    # æ ¹æ®æ•°æ®é›†è‡ªåŠ¨é€‰æ‹©å­¦ä¹ ç‡ï¼ˆè®ºæ–‡4.3.2èŠ‚ï¼šWeibo 0.001, Pheme 0.002ï¼‰
    learning_rate = get_learning_rate(config['data']['train_path'], config)
    logger.info(f"Using learning rate: {learning_rate} (auto-selected based on dataset)")
    
    # ä¼˜åŒ–å™¨ï¼šè®ºæ–‡4.3.2èŠ‚æ˜ç¡®ä¸º Adamï¼ˆé AdamWï¼‰
    # è®ºæ–‡æœªæåŠ weight_decayã€warmupï¼›strict_paper_mode ä¸‹ä¸ä½¿ç”¨ä»»ä½•å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆæ—  warmupï¼‰
    if strict_paper_mode:
        weight_decay = 0.0
        logger.info("Strict paper mode: Adam, weight_decay=0, no warmup (paper not mentioned)")
    else:
        weight_decay = config['training'].get('weight_decay', 1e-4)
        if isinstance(weight_decay, str):
            weight_decay = float(weight_decay)
    
    trainable_params = [p for p in model.parameters() if p.requires_grad]
    optimizer = Adam(
        trainable_params,
        lr=learning_rate,
        weight_decay=weight_decay
    )
    if freeze_encoders:
        logger.info(f"Optimizer only updates {len(trainable_params)} trainable parameter tensors (encoders frozen).")
    
    # ä» checkpoint æ¢å¤ï¼ˆå¯é€‰ï¼‰ï¼šåªåŠ è½½æ¨¡å‹æƒé‡ï¼Œä»ä¸‹ä¸€ epoch ç»§ç»­ï¼›optimizer ä¸åŠ è½½ï¼ˆé¿å…è§£å†»å param group ä¸ä¸€è‡´ï¼‰
    start_epoch = 1
    train_losses = []
    val_losses = []
    train_accs = []
    val_accs = []
    best_val_loss = float('inf')
    resume_from = config.get('training', {}).get('resume_from') or getattr(args, 'resume', None)
    if resume_from:
        resume_path = resume_from if os.path.isabs(resume_from) else os.path.join(os.path.dirname(os.path.abspath(__file__)), resume_from)
        if os.path.exists(resume_path):
            ckpt = torch.load(resume_path, map_location=device)
            model.load_state_dict(ckpt['model_state_dict'], strict=True)
            start_epoch = ckpt.get('epoch', 0) + 1
            best_val_loss = ckpt.get('loss', float('inf'))
            logger.info(f"Resumed from {resume_path}, starting at epoch {start_epoch}, best_val_loss={best_val_loss:.4f}")
        else:
            logger.warning(f"resume_from path not found: {resume_path}, training from scratch.")
    
    # è®­ç»ƒå¾ªç¯
    num_epochs = config['training']['num_epochs']
    save_dir = config['training']['save_dir']
    grad_accum_steps = config['training'].get('grad_accum_steps', 1)
    if grad_accum_steps > 1:
        logger.info(f"Gradient accumulation: {grad_accum_steps} steps (effective batch = {config['data']['batch_size']} * {grad_accum_steps})")
    # æŠ˜ä¸­æ–¹æ¡ˆï¼šæœ€å 1â€“2 ä¸ª epoch åªè§£å†» BERT æœ€åä¸€å±‚ + ResNet æœ€åä¸€ blockï¼Œæå‡ Fake recallï¼Œé€Ÿåº¦å½±å“å°
    unfreeze_last_layers = config.get('training', {}).get('unfreeze_last_layers', False)
    unfreeze_last_epochs = config.get('training', {}).get('unfreeze_last_epochs', 2)
    light_unfreeze_lr = config.get('training', {}).get('light_unfreeze_lr', 1e-5)
    light_unfreeze_lr = float(light_unfreeze_lr)  # YAML å¯èƒ½è§£æä¸º strï¼Œç¡®ä¿ optimizer æ”¶åˆ° float
    unfreeze_start_epoch = max(1, num_epochs - unfreeze_last_epochs + 1) if unfreeze_last_layers else num_epochs + 1
    if unfreeze_last_layers and freeze_encoders:
        logger.info(f"Light unfreeze: from epoch {unfreeze_start_epoch}, BERT last layer + ResNet last block will be unfrozen for {unfreeze_last_epochs} epoch(s), lr={light_unfreeze_lr}")
    logger.info("Starting training...")
    
    for epoch in range(start_epoch, num_epochs + 1):
        # è¿›å…¥â€œæœ€åå‡ è½®â€æ—¶è§£å†» BERT æœ€åä¸€å±‚ + ResNet æœ€åä¸€ blockï¼Œå¹¶åŠ å…¥ä¼˜åŒ–å™¨ï¼ˆpartial ç¼“å­˜æ—¶å‰å‘å·²å« BERT 11 + ResNet 4ï¼Œè§£å†»ç”Ÿæ•ˆï¼‰
        if unfreeze_last_layers and freeze_encoders and epoch == unfreeze_start_epoch:
            newly_trainable = unfreeze_encoder_last_layers(model)
            if newly_trainable:
                optimizer.add_param_group({'params': newly_trainable, 'lr': light_unfreeze_lr})
                logger.info(f"Unfrozen BERT last layer + ResNet last block for final {unfreeze_last_epochs} epoch(s) (lr={light_unfreeze_lr}), added {len(newly_trainable)} param tensors to optimizer.")
        
        logger.info(f"\nEpoch {epoch}/{num_epochs}")
        
        # è®­ç»ƒ
        pgd_config = config['training'].get('pgd', {})
        max_grad_norm = config['training'].get('max_grad_norm', 1.0) if not strict_paper_mode else None
        train_loss, train_acc = train_epoch(
            model, train_loader, criterion, optimizer, device, logger,
            pgd_config, strict_paper_mode, max_grad_norm, grad_accum_steps,
            use_cached_features=use_cached_features
        )
        train_losses.append(train_loss)
        train_accs.append(train_acc)
        
        # éªŒè¯ï¼ˆæ—  val_loader æ—¶è·³è¿‡ï¼Œå¦‚ä»…ç”Ÿæˆäº† train.pt ç¼“å­˜ï¼‰
        if val_loader is not None:
            val_loss, val_acc = validate(
                model, val_loader, criterion, device, logger,
                use_cached_features=use_cached_features
            )
            val_losses.append(val_loss)
            val_accs.append(val_acc)
            logger.info(
                f"Epoch {epoch} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, "
                f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}"
            )
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                save_checkpoint(
                    model, optimizer, epoch, val_loss,
                    os.path.join(save_dir, 'best_model.pt')
                )
            if epoch % config['training']['save_every'] == 0:
                save_checkpoint(
                    model, optimizer, epoch, val_loss,
                    os.path.join(save_dir, f'checkpoint_epoch_{epoch}.pt')
                )
        else:
            val_losses.append(0.0)
            val_accs.append(0.0)
            val_loss = train_loss  # æ—  val æ—¶ç”¨ train_loss å ä½ï¼Œä¾›ä¸‹é¢ save_checkpoint ç”¨
            logger.info(f"Epoch {epoch} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} (no val)")
        
        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆæœ‰ val æ—¶ä¸Šé¢å·²æŒ‰ best ä¿å­˜è¿‡ best_modelï¼‰
        if epoch % config['training']['save_every'] == 0:
            save_checkpoint(
                model, optimizer, epoch, val_loss,
                os.path.join(save_dir, f'checkpoint_epoch_{epoch}.pt')
            )
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        if epoch % config['training']['eval_every'] == 0:
            plot_training_curves(
                train_losses, val_losses, train_accs, val_accs,
                save_path=os.path.join(config['training']['log_dir'], 'training_curves.png')
            )
    
    logger.info("Training completed!")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    save_checkpoint(
        model, optimizer, num_epochs, val_loss,
        os.path.join(save_dir, 'final_model.pt')
    )
    
    # ç»˜åˆ¶æœ€ç»ˆè®­ç»ƒæ›²çº¿
    plot_training_curves(
        train_losses, val_losses, train_accs, val_accs,
        save_path=os.path.join(config['training']['log_dir'], 'final_training_curves.png')
    )


if __name__ == '__main__':
    main()
